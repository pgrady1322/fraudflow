{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "131154eb",
   "metadata": {},
   "source": [
    "# FraudFlow — MLOps Pipeline Showcase\n",
    "\n",
    "**End-to-end demonstration** of the FraudFlow pipeline using synthetic data.\n",
    "\n",
    "This notebook runs without Kaggle credentials — it generates an Elliptic-like Bitcoin transaction dataset with graph structure and known fraud signals.\n",
    "\n",
    "| Stage | Component |\n",
    "|-------|----------|\n",
    "| 1 | Synthetic data generation |\n",
    "| 2 | Graph feature engineering |\n",
    "| 3 | Temporal train/val/test split |\n",
    "| 4 | Model training & evaluation |\n",
    "| 5 | SHAP explainability |\n",
    "| 6 | Model comparison |\n",
    "| 7 | Serving demo |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bc93eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve, roc_auc_score, f1_score,\n",
    "    average_precision_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.features.engineer import build_graph, compute_graph_features\n",
    "from src.data.split import temporal_split\n",
    "from src.training.models import create_model, get_feature_columns\n",
    "from src.training.train import compute_metrics, hybrid_resample\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.RandomState(SEED)\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54ad45c",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Synthetic Data Generation\n",
    "\n",
    "We create 3000 synthetic transactions across 10 timesteps with:\n",
    "- 20 raw features per transaction\n",
    "- ~75% licit, ~15% illicit, ~10% unknown labels\n",
    "- Injected signal: illicit nodes have shifted features 0 & 1\n",
    "- ~6000 directed edges (random graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9feeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NODES = 3000\n",
    "N_FEATURES = 20\n",
    "N_TIMESTEPS = 10\n",
    "\n",
    "# Generate transactions\n",
    "tx_ids = np.arange(N_NODES)\n",
    "timesteps = rng.randint(1, N_TIMESTEPS + 1, size=N_NODES)\n",
    "features = rng.randn(N_NODES, N_FEATURES)\n",
    "\n",
    "# Labels\n",
    "labels = rng.choice([0, 1, -1], size=N_NODES, p=[0.75, 0.15, 0.10])\n",
    "\n",
    "# Inject learnable signal for illicit transactions\n",
    "illicit_mask = labels == 1\n",
    "features[illicit_mask, 0] += 2.0   # Strong shift on feature 0\n",
    "features[illicit_mask, 1] -= 1.5   # Shift on feature 1\n",
    "features[illicit_mask, 2] += 0.8   # Mild shift on feature 2\n",
    "\n",
    "# Build DataFrame\n",
    "feat_cols = [f'feat_{i}' for i in range(N_FEATURES)]\n",
    "df = pd.DataFrame(features, columns=feat_cols)\n",
    "df.insert(0, 'txId', tx_ids)\n",
    "df.insert(1, 'timestep', timesteps)\n",
    "df['label'] = labels\n",
    "\n",
    "# Generate edges\n",
    "N_EDGES = N_NODES * 2\n",
    "src_nodes = rng.randint(0, N_NODES, size=N_EDGES)\n",
    "dst_nodes = rng.randint(0, N_NODES, size=N_EDGES)\n",
    "edges_df = pd.DataFrame({'txId1': src_nodes, 'txId2': dst_nodes})\n",
    "edges_df = edges_df[edges_df['txId1'] != edges_df['txId2']].drop_duplicates()\n",
    "\n",
    "print(f'Transactions: {len(df):,}')\n",
    "print(f'Edges:        {len(edges_df):,}')\n",
    "print(f'Label dist:   {dict(zip(*np.unique(labels, return_counts=True)))}')\n",
    "print(f'Timesteps:    {sorted(df[\"timestep\"].unique())}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576c9a48",
   "metadata": {},
   "source": [
    "### Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da792522",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Overall label distribution\n",
    "label_map = {0: 'Licit', 1: 'Illicit', -1: 'Unknown'}\n",
    "label_counts = df['label'].map(label_map).value_counts()\n",
    "colors = {'Licit': '#2ecc71', 'Illicit': '#e74c3c', 'Unknown': '#95a5a6'}\n",
    "label_counts.plot.bar(ax=axes[0], color=[colors[l] for l in label_counts.index])\n",
    "axes[0].set_title('Overall Label Distribution')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Labels per timestep\n",
    "known = df[df['label'] != -1]\n",
    "ts_label = known.groupby(['timestep', 'label']).size().unstack(fill_value=0)\n",
    "ts_label.columns = ['Licit', 'Illicit']\n",
    "ts_label.plot.bar(stacked=True, ax=axes[1], color=['#2ecc71', '#e74c3c'])\n",
    "axes[1].set_title('Labels per Timestep')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xlabel('Timestep')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4fcb25",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Graph Feature Engineering\n",
    "\n",
    "Build a directed graph from the edgelist and compute topology features:\n",
    "- **Degree** (total, in, out)\n",
    "- **PageRank** — global importance in the transaction network\n",
    "- **Clustering coefficient** — local connectivity structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_graph(edges_df)\n",
    "print(f'Graph: {G.number_of_nodes():,} nodes, {G.number_of_edges():,} edges')\n",
    "\n",
    "# Compute graph features\n",
    "enriched = compute_graph_features(df.copy(), G, ['degree', 'pagerank', 'clustering_coefficient'])\n",
    "print(f'Enriched features: {enriched.shape[1]} columns')\n",
    "enriched[['txId', 'graph_degree', 'graph_in_degree', 'graph_out_degree', 'graph_pagerank', 'graph_clustering_coeff']].describe().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a subgraph colored by label\n",
    "sample_nodes = list(range(200))  # First 200 nodes\n",
    "G_sub = G.subgraph([n for n in sample_nodes if n in G])\n",
    "\n",
    "node_colors = []\n",
    "for n in G_sub.nodes():\n",
    "    lbl = df.loc[df['txId'] == n, 'label'].values\n",
    "    if len(lbl) > 0 and lbl[0] == 1:\n",
    "        node_colors.append('#e74c3c')  # illicit = red\n",
    "    elif len(lbl) > 0 and lbl[0] == 0:\n",
    "        node_colors.append('#2ecc71')  # licit = green\n",
    "    else:\n",
    "        node_colors.append('#95a5a6')  # unknown = gray\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "pos = nx.spring_layout(G_sub, seed=SEED, k=0.3)\n",
    "nx.draw_networkx(\n",
    "    G_sub, pos, ax=ax,\n",
    "    node_color=node_colors, node_size=40, with_labels=False,\n",
    "    edge_color='#bdc3c7', alpha=0.8, width=0.5, arrows=False,\n",
    ")\n",
    "ax.set_title('Transaction Subgraph (200 nodes) — Red=Illicit, Green=Licit, Gray=Unknown')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d506e93",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Temporal Train / Val / Test Split\n",
    "\n",
    "Split by timestep to prevent data leakage:\n",
    "- **Train**: timesteps 1–7\n",
    "- **Val**: timesteps 8–9\n",
    "- **Test**: timestep 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cdbcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "tmp = Path(tempfile.mkdtemp())\n",
    "processed_dir = tmp / 'processed'\n",
    "splits_dir = tmp / 'splits'\n",
    "processed_dir.mkdir()\n",
    "\n",
    "# Save enriched features\n",
    "enriched.to_parquet(processed_dir / 'features.parquet', index=False)\n",
    "\n",
    "# Split\n",
    "stats = temporal_split(\n",
    "    features_path=processed_dir / 'features.parquet',\n",
    "    splits_dir=splits_dir,\n",
    "    train_ts=(1, 7),\n",
    "    val_ts=(8, 9),\n",
    "    test_ts=(10, 10),\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "train_df = pd.read_parquet(splits_dir / 'train.parquet')\n",
    "val_df = pd.read_parquet(splits_dir / 'val.parquet')\n",
    "test_df = pd.read_parquet(splits_dir / 'test.parquet')\n",
    "\n",
    "print(f\"Train: {len(train_df):,} (illicit: {(train_df['label']==1).sum():,})\")\n",
    "print(f\"Val:   {len(val_df):,} (illicit: {(val_df['label']==1).sum():,})\")\n",
    "print(f\"Test:  {len(test_df):,} (illicit: {(test_df['label']==1).sum():,})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa273734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split composition visualization\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "split_data = pd.DataFrame({\n",
    "    'Split': ['Train', 'Train', 'Val', 'Val', 'Test', 'Test'],\n",
    "    'Label': ['Licit', 'Illicit'] * 3,\n",
    "    'Count': [\n",
    "        (train_df['label']==0).sum(), (train_df['label']==1).sum(),\n",
    "        (val_df['label']==0).sum(), (val_df['label']==1).sum(),\n",
    "        (test_df['label']==0).sum(), (test_df['label']==1).sum(),\n",
    "    ]\n",
    "})\n",
    "sns.barplot(data=split_data, x='Split', y='Count', hue='Label',\n",
    "            palette={'Licit': '#2ecc71', 'Illicit': '#e74c3c'}, ax=ax)\n",
    "ax.set_title('Label Distribution per Split')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e51be1",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Training\n",
    "\n",
    "Train an XGBoost classifier with hybrid resampling and auto `scale_pos_weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = get_feature_columns(train_df)\n",
    "print(f'Features: {len(feature_cols)}')\n",
    "\n",
    "X_train = train_df[feature_cols].fillna(0).values\n",
    "y_train = train_df['label'].values\n",
    "X_val = val_df[feature_cols].fillna(0).values\n",
    "y_val = val_df['label'].values\n",
    "X_test = test_df[feature_cols].fillna(0).values\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# Hybrid resampling\n",
    "X_train_r, y_train_r = hybrid_resample(\n",
    "    X_train, y_train,\n",
    "    max_majority=1500, target_minority_ratio=0.3, seed=SEED\n",
    ")\n",
    "print(f'After resampling: {len(X_train_r):,} samples '\n",
    "      f'({(y_train_r==1).sum():,} illicit, {(y_train_r==0).sum():,} licit)')\n",
    "\n",
    "# Train\n",
    "n_pos = int((y_train_r == 1).sum())\n",
    "n_neg = int((y_train_r == 0).sum())\n",
    "model = create_model('xgboost', {\n",
    "    'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1,\n",
    "    'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "    'eval_metric': 'aucpr', 'random_state': SEED,\n",
    "}, n_pos, n_neg)\n",
    "\n",
    "model.fit(X_train_r, y_train_r, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "# Evaluate\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_prob = model.predict_proba(X_val)[:, 1]\n",
    "val_metrics = compute_metrics(y_val, y_val_pred, y_val_prob)\n",
    "\n",
    "print('\\n─── Validation Metrics ───')\n",
    "for k, v in val_metrics.items():\n",
    "    print(f'  {k:25s} {v:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a15077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    imp = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=True).tail(15)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.barh(imp['feature'], imp['importance'], color='#3498db')\n",
    "    ax.set_title('XGBoost Feature Importance (Top 15)')\n",
    "    ax.set_xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ddf9cb",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Evaluation — Test Set\n",
    "\n",
    "Evaluate the trained model on the held-out test set (timestep 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27afa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "test_metrics = compute_metrics(y_test, y_test_pred, y_test_prob)\n",
    "\n",
    "print('─── Test Metrics ───')\n",
    "for k, v in test_metrics.items():\n",
    "    print(f'  {k:25s} {v:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669da33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Licit', 'Illicit'], yticklabels=['Licit', 'Illicit'])\n",
    "axes[0].set_title('Confusion Matrix')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_prob)\n",
    "axes[1].plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {test_metrics[\"auc_roc\"]:.3f}')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.4)\n",
    "axes[1].set_title('ROC Curve')\n",
    "axes[1].set_xlabel('FPR')\n",
    "axes[1].set_ylabel('TPR')\n",
    "axes[1].legend()\n",
    "\n",
    "# Precision-Recall curve\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_test_prob)\n",
    "axes[2].plot(rec, prec, 'r-', linewidth=2, label=f'AP = {test_metrics[\"auc_pr\"]:.3f}')\n",
    "axes[2].set_title('Precision-Recall Curve')\n",
    "axes[2].set_xlabel('Recall')\n",
    "axes[2].set_ylabel('Precision')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.suptitle('Test Set Evaluation', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df9d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_pred, target_names=['Licit', 'Illicit'], zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a5439",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. SHAP Explainability\n",
    "\n",
    "Using TreeExplainer to understand which features drive fraud predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Handle 3D output from binary classifier\n",
    "if isinstance(shap_values.values, np.ndarray) and shap_values.values.ndim == 3:\n",
    "    shap_values = shap.Explanation(\n",
    "        values=shap_values.values[:, :, 1],\n",
    "        base_values=shap_values.base_values[:, 1] if shap_values.base_values.ndim > 1 else shap_values.base_values,\n",
    "        data=shap_values.data,\n",
    "        feature_names=feature_cols,\n",
    "    )\n",
    "else:\n",
    "    shap_values.feature_names = feature_cols\n",
    "\n",
    "print(f'SHAP values computed for {len(shap_values.values)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9491890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global feature importance (bar)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "shap.plots.bar(shap_values, max_display=15, show=False, ax=ax)\n",
    "ax.set_title('SHAP Global Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283446d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "shap.plots.beeswarm(shap_values, max_display=15, show=False)\n",
    "plt.title('SHAP Beeswarm — Feature Impact Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall for a high-confidence illicit prediction\n",
    "illicit_idx = np.where(y_test == 1)[0]\n",
    "top_illicit = illicit_idx[np.argmax(y_test_prob[illicit_idx])]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "shap.plots.waterfall(shap_values[top_illicit], max_display=12, show=False)\n",
    "plt.title(f'SHAP Waterfall — Illicit Transaction (P={y_test_prob[top_illicit]:.3f})')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c253a8b",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Model Comparison\n",
    "\n",
    "Compare XGBoost, Random Forest, and Logistic Regression on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_compare = {\n",
    "    'XGBoost': ('xgboost', {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}),\n",
    "    'Random Forest': ('random_forest', {'n_estimators': 100, 'max_depth': 10}),\n",
    "    'Logistic Reg': ('logistic_regression', {'max_iter': 1000, 'C': 1.0}),\n",
    "}\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for name, (model_type, params) in models_to_compare.items():\n",
    "    m = create_model(model_type, params, n_pos, n_neg)\n",
    "    \n",
    "    if model_type == 'xgboost':\n",
    "        m.fit(X_train_r, y_train_r, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    else:\n",
    "        m.fit(X_train_r, y_train_r)\n",
    "    \n",
    "    yp = m.predict(X_test)\n",
    "    yprob = m.predict_proba(X_test)[:, 1] if hasattr(m, 'predict_proba') else yp.astype(float)\n",
    "    \n",
    "    metrics = compute_metrics(y_test, yp, yprob)\n",
    "    metrics['model'] = name\n",
    "    comparison_results.append(metrics)\n",
    "    print(f'{name:18s}  F1={metrics[\"f1_illicit\"]:.3f}  AUC-ROC={metrics[\"auc_roc\"]:.3f}  AUC-PR={metrics[\"auc_pr\"]:.3f}')\n",
    "\n",
    "comp_df = pd.DataFrame(comparison_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d857a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped bar chart comparison\n",
    "metric_cols = ['f1_illicit', 'auc_roc', 'auc_pr', 'precision_illicit', 'recall_illicit']\n",
    "plot_df = comp_df.melt(id_vars='model', value_vars=metric_cols, var_name='Metric', value_name='Score')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.barplot(data=plot_df, x='Metric', y='Score', hue='model', ax=ax,\n",
    "            palette=['#3498db', '#2ecc71', '#e67e22'])\n",
    "ax.set_title('Model Comparison — Test Set Metrics')\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend(title='Model')\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.2f', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd64decd",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. FastAPI Serving Demo\n",
    "\n",
    "FraudFlow includes a production-ready FastAPI endpoint with Prometheus metrics.\n",
    "\n",
    "```bash\n",
    "# Launch serving\n",
    "make serve\n",
    "\n",
    "# Or via CLI\n",
    "fraudflow serve --port 8000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea252f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: how to call the serving endpoint\n",
    "# (Not executed here — requires running server)\n",
    "\n",
    "EXAMPLE_CODE = '''\n",
    "import httpx\n",
    "\n",
    "# Health check\n",
    "resp = httpx.get(\"http://localhost:8000/health\")\n",
    "print(resp.json())\n",
    "# {\"status\": \"healthy\", \"model_loaded\": true, \"model_type\": \"XGBClassifier\", \"uptime_sec\": 12.3}\n",
    "\n",
    "# Single prediction\n",
    "resp = httpx.post(\"http://localhost:8000/predict\", json={\n",
    "    \"features\": [sample_features.tolist()]\n",
    "})\n",
    "result = resp.json()\n",
    "print(f\"Prediction: {result['predictions'][0]}\")\n",
    "print(f\"P(illicit): {result['probabilities'][0]:.3f}\")\n",
    "print(f\"Inference:  {result['inference_time_ms']:.1f}ms\")\n",
    "\n",
    "# Prometheus metrics\n",
    "resp = httpx.get(\"http://localhost:8000/metrics\")\n",
    "print(resp.text[:500])  # Prometheus text format\n",
    "'''\n",
    "\n",
    "print('API endpoints:')\n",
    "print('  GET  /health     — Service health + model status')\n",
    "print('  POST /predict    — Batch fraud predictions')\n",
    "print('  GET  /model/info — Model metadata')\n",
    "print('  GET  /metrics    — Prometheus scrape endpoint')\n",
    "print()\n",
    "print('Example client code:')\n",
    "print(EXAMPLE_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc46bff",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Component | Status | Details |\n",
    "|-----------|--------|---------|\n",
    "| **Data Pipeline** | DVC 5-stage | download → featurize → split → train → evaluate |\n",
    "| **Graph Features** | 6 columns added | degree (in/out), PageRank, clustering coefficient |\n",
    "| **Temporal Split** | No leakage | Train ≤ ts7, Val ts8-9, Test ts10 |\n",
    "| **Best Model** | XGBoost | See comparison chart above |\n",
    "| **Explainability** | SHAP | Global importance + per-transaction waterfall |\n",
    "| **Experiment Tracking** | MLflow | `make mlflow-ui` to view |\n",
    "| **HP Tuning** | Optuna | `make tune` for automated search |\n",
    "| **Drift Monitoring** | Evidently | `make drift` for HTML reports |\n",
    "| **Serving** | FastAPI + Prometheus | `make serve` → localhost:8000 |\n",
    "| **CI/CD** | GitHub Actions | Lint → Test → Docker build |\n",
    "| **Container** | Docker multi-stage | `make docker` to build |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
